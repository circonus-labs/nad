#!/usr/bin/env node
// -*-Javascript-*-
/* eslint-disable */
'use strict';
//
// Toss executables (scripts too) in /etc/node-agent.d
// Each program should produce lines as follows:
//    <name><whitespace><type>
// or:
//    <name><whitespace><type><whitespace><value>
//
// The first indicates the value is present and null
// the second indicates the value is present and specific
//

// require //////////////////////////////////////////////////////////////

var fs = require('fs'),
    os = require('os'),
    tls = require('tls'),
    http = require('http'),
    https = require('https'),
    url = require('url'),
    path = require('path'),
    crypto = require('crypto'),
    circapi = require('circonusapi2'),
    nadapi = require('nad_circapi'),
    circwmi = require('circwmi'),
    dutil = require('debug_util'),
    spawn = require('child_process').spawn;

// "globals" ///////////////////////////////////////////////////////////

var booted = false;
var ext = /(?:\.([^.]+))?$/;

// cache of previous results of running scripts
// this is responded with if a script is still running when
// a request for a new value comes in (which is common with long
// running scripts that periodically output values)
var past_results = {};

// a data structure representing all scripts (aka plugins/native
// plugins.)  Each value in the object contains an object that
// has properties relating to the script.
var scripts = {};

// a collection indicating which scripts that have been run once
// already
var scripts_once = {};

var push_script = undefined;

// ssl credentials
var creds = {};

// The UID that we should attempt to "drop" to if specified
// on the command line so we don't have to keep running as root
var drop_uid = 0;

// The script "generation".  A global counter that's incremented
// each time we scan for new scripts on disk.
var generation = 0;

// a flag set from the command line that indicates we just want
// to run the index and then exit
var do_index = false;

// command line options for api setup
var api_options = {};
var api_setup = false;
var attempt_reverse = false;
var auth_token = null;
var target = null;
var cafile = null;
var hostname = os.hostname();
var check_bundle_id = null;
var brokerid = null
var configfile = null;
var debugdir = null;                        // if set, a dir to write debug logs to
var wipedebugdir = false;                  // if true, wipe debug logs clean before each write
var platform = process.platform;
var is_windows = (platform === "win32");    // windows

// procre is a regular expression that captures
// the main part of a filename (i.e. without)
var procre = null;
if (is_windows) {
  procre = /^(?!\.)([^\\]*?)(?:\..*)$/;
} else {
  procre = /^(?!\.)([^\/]*?)(?:\..*)$/;
}

var configdir = '/opt/circonus/etc/node-agent.d',
    port = [],
    defaultport = [ [ 2609, null ] ],
    sslport = [],
    verify = false;

////////////////////////////////////////////////////////////////////////
// help
////////////////////////////////////////////////////////////////////////

function help(err) {
  console.log(process.argv[1] + "\n" +
              "\t-h\t\t\tthis help message\n" +
              "\t-i\t\t\toffline inventory\n" +
              "\t-c <configdir>\t\tconfig dir\n" +
              "\t-p [ip:]<port>\t\tunsecured port\n" +
              "\t-s [ip:]<secureport>\tsecured port\n" +
              "\t-v\t\t\tverify secured traffic\n" +
              "\t-r\t\t\tattempt reverse connection\n" +
              "\t--authtoken\t\tCirconus API auth token to use, if passed will attempt to configure via the Circonus API then exit.\n" +
              "\t--target\t\tTarget Circonus will use to contact this host.\n" +
              "\t--hostname\t\tHostname used in check and graph names, if not passed we will attempt to look it up.\n" +
              "\t--brokerid\t\tID of the Circonus broker to configure the check on.\n" +
              "\t--cid\t\tID of the Circonus check bundle which we will use to find the proper broker for reverse connections.\n" +
              "\t--cafile\t\tpath to CA certificate file.\n" +
              "\t--configfile\t\tName of the file in the config directory to use for Circonus configuration.\n" +
              "\t--debugdir\t\tCreate debug files for each script and write them to this directory.\n" +
              "\t--wipedebugdir\t\tWipe debug files clean before each write.\n" +
              "\t--apihost\t\tOverride the host for the Circonus API server (default: api.circonus.com)\n" +
              "\t--apiport\t\tOverride the port for the Circonus API server (default: 443)\n" +
              "\t--apipath\t\tOverride the path for the Circonus API server (default: /v2)\n" +
              "\t--apiprotocol\t\tOverride the protocol for the Circonus API server (default: https)\n" +
              "\t--apiverbose\t\tOutput API traffic to STDERR\n"
            );
  if(err) {
    console.error("Error:", err);
    process.exit(-1);
  }
}

////////////////////////////////////////////////////////////////////////
// index
////////////////////////////////////////////////////////////////////////

// this code is used to generate an "index" of what is in the
// in the config directory.  It's triggered by passing the "-i"
// flag on the command line

function index(dir) {

  // attempt to change to this directory or die trying
  try { process.chdir(dir); }
  catch (e) {
    console.error("Cannot use configdir:", configdir, e);
    process.exit(-1);
  }

  // a collection of files that are listed in the JSON in the catalog
  // files (the ".index.json" files) in each directory
  var catalog = {};

  var active  = {};

  // a collection of files that are "missing" (i.e. listed in the catalog
  // files but not in the directories / inaccessible somehow)
  var missing = {};

  // a recursive function that once called will recurse down through
  // the directories reading the ".index.json" files and examining the
  // files and popuating the catalog / active / missing variables
  function build_catalog(dir) {
    dir = dir || "";

    // attempt to read the ".index.json" catalog file in the directory
    // passed in, and then process each entry in that catalog.
    // Remember each file that isn't in the directory
    try {
      var c = fs.readFileSync(path.join(".", dir, ".index.json"));
      var j = JSON.parse(c);
      catalog[dir] = j;
      for(var script in j) {
        try {
          var info = fs.statSync(path.join(".", dir, script));
          if(!info.isFile() || (!(is_windows) && (!(info.mode & parseInt('0100',8))))) throw Exception("");
        } catch(e) { missing[path.join(dir, script)] = true; }
      }
    } catch(e) { }

    // recurse into all subdirectories and call ourselves again
    var files = fs.readdirSync(path.join(".", dir));
    for(var i=0; i<files.length; i++) {
      var info = fs.statSync(path.join(".", dir, files[i]));
      if(info && info.isDirectory()) {
        build_catalog(path.join(dir, files[i]));
      }
    }
  }
  build_catalog();

  // read the actual scripts in the config directory
  // ...run the loop for each
  var files = fs.readdirSync(".");
  var base = fs.realpathSync(".") + path.sep;
  for(var i=0; i<files.length; i++) {
    var m = procre.exec(files[i]);
    if(!m) continue;
    var extension = ext.exec(files[i])[1];
    if ((extension === "conf") || (extension === "json")) continue;
    var info = fs.lstatSync(files[i]);
    var realpath = files[i];
    if(info.isSymbolicLink()) info = fs.statSync(files[i]);

    // if this is executable (or we're running on windows)
    if(info.isFile() && (is_windows || info.mode & parseInt('0100',8))) {
      var realpath = fs.realpathSync(files[i]);
      if(realpath.indexOf(base) == 0)
        realpath = realpath.substr(base.length);
      active[realpath] = m[1];
    }
  }

  // generate debug output
  for(var module in catalog) {
    for(var script in catalog[module]) {
      var m = procre.exec(script);
      if(!m) console.log("! " + script + ": MALFORMED NAME");
      else {
        var extension = ext.exec(script)[1];
        if ((extension === "conf") || (extension === "json")){
          console.log("! " + script + ": CANNOT EXECUTE " + extension + " FILES");
          continue;
        }
        var file = path.join(module, script);
        var desc = catalog[module][script];
        var on = (file in active) ? "*" : " ";
        if(file in missing) on = "!";
        delete active[file];
        console.log(on + " " +
                    path.join(module, m[1]) + ": " + desc);
      }
    }
  }
  var first = true;
  for(var file in active) {
    if(first) { console.log("\n  !!! Rogue scripts !!!"); first = false; }
    console.log("* " + file + ": ???");
  }
}

////////////////////////////////////////////////////////////////////////
// process commmand line arguments
////////////////////////////////////////////////////////////////////////

for(var i=2; i<process.argv.length; i++) {
  switch(process.argv[i]) {

    // display help
    case "-h": help(); process.exit(-1);

    // set the config dir
    // (internally we resolve this to the real path after processing symlinks)
    case "-c": configdir = fs.realpathSync(process.argv[++i]); break;

    // offline inventory
    case "-i": do_index = true; break;

    // switch to this uid after starting
    // (only if node supports it on the host os)
    case "-u": drop_uid = parseInt(process.argv[++i]); break;

    // specify one or more ports (and, optionally, IP) to listen for
    // http requests on either in the form "8080" or "127.0.0.1:8080"
    case "-p": {
      var p = process.argv[++i].split(/:/);
      if(p.length == 1) p.unshift(null);
      if(p.length != 2) help("-p [ip:]port");
      port.push( [ parseInt(p[1]), p[0] ] );
      break;
    }

    // specify one or more ports (and, optionally, IP) to listen for
    // https requests on either in the form "4443" or "127.0.0.1:4443"
    case "-s": {
      var p = process.argv[++i].split(/:/);
      if(p.length == 1) p.unshift(null);
      if(p.length != 2) help("-s [ip:]port");
      sslport.push( [ parseInt(p[1]), p[0] ] );
      break;
    }

    // should we verify using a certificate authority the
    // SSL certificate presented?
    case "-v": verify = true; break;

    //// options for autoconfig with circonus api ////

    case "--authtoken": {
        auth_token = process.argv[++i];
        api_setup=true;
        break;
    }
    case "-r": attempt_reverse = true; break;
    case "--target": target = process.argv[++i]; break;
    case "--cid": check_bundle_id = process.argv[++i]; break;
    case "--hostname": hostname = process.argv[++i]; break;
    case "--brokerid": brokerid = process.argv[++i]; break;
    case "--cafile": cafile = process.argv[++i]; break;
    case "--configfile": configfile = fs.realpathSync(process.argv[++i]); break;
    case "--debugdir": debugdir = process.argv[++i]; break;
    case "--wipedebugdir": wipedebugdir = true; ++i; break;
    case "--apihost": api_options['host'] = process.argv[++i]; break;
    case "--apiport": api_options['port'] = process.argv[++i]; break;
    case "--apipath": api_options['path'] = process.argv[++i]; break;
    case "--apiprotocol": api_options['protocol'] = process.argv[++i]; break;
    case "--apiverbose": api_options['verbose'] = true; break;

    //// unknown option, just display the helptext ////

    default: help("unknown argument: " + process.argv[i]);
  }
}

if (attempt_reverse) api_setup = false;

// if we're just indexing, do that then quit
if(do_index) {
  index(configdir);
  process.exit(0);
}

// if we're just setting up circonus, do that
if(api_setup) {
  configure_circonus();
}

// setup ports / ssl
if(port.length == 0) port = defaultport;
if(port.length == 0 && sslport.length == 0)
  help("must specify at least one of -p and -s");
if(sslport.length > 0) {
  try {
    // Setup creds
    creds.key = fs.readFileSync(path.join(configdir, "na.key")).toString();
    creds.cert = fs.readFileSync(path.join(configdir, "na.crt")).toString();
    if(verify) creds.ca = fs.readFileSync(path.join(configdir, "na.ca")).toString();
  } catch(e) {
    console.error("Make sure:");
    console.error("\tyour key is available: " + path.join(configdir, "na.key"));
    console.error("\tyour cert is available: " + path.join(configdir, "na.crt"));
    if(verify)
      console.error("\tyour ca is available: " + path.join(configdir, "na.ca"));
    console.error("\n" + e);
    process.exit(-1);
  }
}

////////////////////////////////////////////////////////////////////////
// scanning for plugins (both native and non-native)
////////////////////////////////////////////////////////////////////////

// a handy function returning a callback that will
// determine if a file has changed on not.
// Used by rescan_modules
function onchange(cb) {
  return function(c,p) {
    if(c.ino != p.ino || c.size != p.size || c.mtime.valueOf() != p.mtime.valueOf() || c.mode != p.mode)
      cb();
  };
}

// run each script in scripts that hasn't had an initial
// run yet (and then remember it _has_ had an initial run)
function initial_pass() {
  for(var which in scripts) {
    if(!(which in scripts_once)) {
      init_script(scripts[which], null, function() {});
      scripts_once[which] = true;
    }
  }
  if(!booted) {
    post_boot();
    booted = true;
  }
}

// look on disk for updates to the config dir where
// we keep all our modules (aka plugins / aka scripts)
function rescan_modules() {

  // this keeps track of how many filesystem stats we have
  // "in progress" and are still waiting for callbacks on
  var progress = 0;

  // this is a handy private function that goes through
  // all the scripts in our scripts object and removes
  // any that haven't had their generation number updated
  // to our current generation number once we've done
  // scanning
  var sweep = function () {

    // don't do this while we're still waiting for
    // stat requests that are in progress
    if(progress != 0) return;

    // clear out any out of date scripts
    for(var t in scripts) {
      if(scripts[t].generation < generation) {
        fs.unwatchFile(scripts[t].command);
        delete scripts[t];
        delete scripts_once[t];
      }
    }

    // run the initial run for any new scripts
    initial_pass();
  };

  // generation is the global number of times rescan_modules has been
  // called.  Each time we rescan our modules we increase it
  // by one.
  generation++;

  // look in the config directory
  fs.readdir(configdir, function(err, files) {

    // bomb out if there's any error (we don't do any fancy
    // error handling or attempt any form of recovery)
    if (err) {
      console.error("Can't read config dir '"+configdir+"':", err);
      process.exit(-1);
    }

    // inc our reference count
    progress++;

    // for each file in the config directory
    for(var i = 0; i < files.length; i++) {

      // check if the file is of the form something.something
      // and if it doen't match, ignore this file
      // (this regex will contain a platform dependent regex)
      var m = procre.exec(files[i]);
      if(!m) continue;

      // ignore files that are something.conf or something.json
      // these are config files, not plugins
      var extension = ext.exec(files[i])[1];
      if ((extension === "conf")||(extension === "json")) continue;

      var filename = path.join(configdir, files[i]);

      // stop watching the file for updates
      fs.unwatchFile(filename);

      // note we need to wait for another stat callback to be
      // called before we're done
      progress++;

      // stat the file
      fs.stat(filename, (function(filename, name) {
        return function(serr, sb) {

          // rewatch the file for future updates.  i.e. if the file changes
          // again later then retrigger this rescan_modules routine
          if(sb && sb.isFile())
            fs.watchFile(filename, onchange(rescan_modules));

          // if the file is something we should deal with
          // (is a file, and either ends in .js or is executable, or we're running on
          // windows where everything is considered executable)
          if(sb && sb.isFile() && (is_windows || /\.js$/.test(filename) || sb.mode & parseInt('0111',8))) {
            // setup the details in the scripts object for this file
            if(!(name in scripts)) scripts[name] = {};
            var d = scripts[name];
            d.name = name;
            d.generation = generation;
            d.command = filename;
            d.native_plugin = /\.js$/.test(filename);
            d.running = false;
            d.sb = sb;

            // if this is a "native plugin", i.e. a plugin written in
            // javascript with a ".js" extension then simply load
            // the code directly into node and then create
            // an instance 'obj' to shove in the scripts data structure
            if(d.native_plugin) {
              var module = require(d.command);
              d.obj = new module();
            }

            // Only remove items on initial scan
            if (generation == 1) {
              dutil.init_debug(name, debugdir);
            }
          }
          progress--;
          sweep();
        }
      })(filename,m[1]));
    }
    progress--;
    sweep();
  });
}

////////////////////////////////////////////////////////////////////////
// executing scripts
////////////////////////////////////////////////////////////////////////

function init_script(d, req, cb) {
  if(d.running) {
    cb(d, past_results[d.name], d.name);
    return;
  }

  get_config(req, d, cb);
}

// per script config
function get_config(req, d, cb) {
  console.log(d.name);
  fs.exists(path.join(configdir, d.name + ".json"), function(exists) {
    if ( exists ) {
      //console.log("hey, a config file");
      fs.readFile(path.join(configdir, d.name + ".json"), function(err, data) {
        if (err) throw err;
        var json_config = JSON.parse(data);

        //console.log(json_config);

        var instance_count = 0;
        for ( var instance in json_config ) instance_count++;

        // Add the number of time we will run this script to our
        // total run_count so we don't finish early.
        if ( instance_count > 1 ) req.nad_run_count += instance_count - 1;
        for ( var instance in json_config ) {
          run_script(d, cb, req, json_config[instance], d.name + "`" + instance);
        }
      });
    }
    else {
      run_script(d, cb, req, [], d.name);
    }
  });
}

// utility function;  Returns the callback wrapped in an
// additional function that that stores the results in
// past results before calling the callback
function past_set_cb(cb) {
  return function(_d, _r, _i) {
    past_results[_i] = _r;
    cb(_d,_r,_i);
  }
};

// merge_types takes two char type descriptors and returns the
// smallest type that could non-erroneously represent them
function merge_types(a,b) {
  if(a == b) return a;
  // There are four source cases where we can upgrade to int64_t
  if(a == 'i' && (b == 'I' || b == 'l')) return 'l';
  if(a == 'I' && (b == 'i' || b == 'l')) return 'l';
  if(a == 'l' && (b == 'i' || b == 'I')) return 'l';
  if(a == 'L' && b == 'I') return 'l';
  // otherwise we have to just jump to a double
  return 'n';
}

// runs a single script / native plugin and then fire a callback
//   d is the object for the script that's stored in 'scripts'
//   cb is what we call back when done
//   req is the request object (passed to native plugins)
//   args is any arguments that came from the per script config file
//   instance is
function run_script(d, cb, req, args, instance) {

  // mark it as running
  // (we don't re-run scripts that are still running)
  d.running = true;

  // per process data
  var proc_data = {
    // incomplete line of data buffered between
    // callbacks.  This will be
    data: '',

    // complete lines of data that have yet to
    // be handled (parsed for JSON and/or tab
    // file format.)  We only parse the output
    // when we reach the end of the output or a
    // blank line
    lines: [],

    options: {}
  };

  // mark that we're starting now
  d.last_start = +(new Date());

  // if this is a native plugin then all we need to do
  // is call the run method on the instance stored within d.obj
  // and we're done, so return
  if(d.native_plugin) {
    d.obj.run(d, past_set_cb(cb), req, args, instance);
    return;
  }

  // execute the command
  var cmd = spawn(d.command, args);
  var kill_func = function() {
    cmd.stdin.destroy();
    cmd.stdout.destroy();
    cmd.stderr.destroy();
    cmd.kill();
  };

  // create a function that can handle output from the process we
  // just created.  This will be called from the code below whenever
  // we reach the end of the process output, or a blank line is found in
  // the output
  var handle_output = function(d, cb, instance) {
    if(proc_data.timeout) clearTimeout(proc_data.timeout);
    d.last_finish = +(new Date());
    var i, results = {}, parts;

    // if someone has specified a debug dir, then log out
    // the record we collected to that
    if (debugdir) {
      dutil.write_debug_output(d.name, proc_data.lines, debugdir, wipedebugdir);
    }

    // attempt to process the lines as json...
    try { results = JSON.parse(proc_data.lines.join(' ')); }
    catch(e) {
      // ... but if that doesn't work, try the tab delim format
      for(i=0; i<proc_data.lines.length; i++) {
        var name, type, space, val, isnull;
        parts = /^\s*(metric\s+)?(\S+)\s+(string|int|float|[iIlLns])(\s*)(.*)$/.exec(proc_data.lines[i]);
        if (parts) {
          name = parts[2];
          type = parts[3];
          space = parts[4];
          val = parts[5];
          isnull = (space.length == 0 || val == "[[null]]");
          type = type.length > 1 ? type === "float" ? "n" : type.substr(0,1) : type;
          if (type != 's' &&  // this is numeric
              results.hasOwnProperty(name) && results[name]._type != 's' && // preexists as numeric
              results[name].hasOwnProperty("_value")) {
            if(!Array.isArray(results[name]._value)) { // upgrade to array
              results[name]._value = [ results[name]._value ];
            }
            // we're in a position to append the result instead of set it.
            results[name]._value.push(isnull ? null : val);
            // we also might need to "upgrade the type"
            results[name]._type = merge_types(type, results[name]._type);
          } else {
            results[name] = { '_type': type,
                              '_value': isnull ? null : val
                            };
          }
        }
      }
    }

    // remember the past results
    past_results[instance] = results;

    // execute the callback
    cb(d, results, instance);
  };

  // hook up the process so whenever we complete reading data
  // from the process we call "handle_output" and process
  // any remaining data (i.e. any partial line still in
  // our between callback buffer)
  cmd.stdout.on('end', function() {
    handle_output(d, cb, instance);
  });

  // hook up an anonymous function to the process to be called
  // whenever we get output.  The way this works is basically
  // there's two buffers used between calls: proc_data.lines
  // representing all lines of data we haven't processed yet
  // and proc_data.data representing an incomplete line
  cmd.stdout.on('data', function(buff) {
    var offset;

    // append output we collected to the incomplete line buffer
    // we're using to cache data between "data" callbacks
    proc_data.data = proc_data.data + buff;

    // extract each complete line of data that's in the
    // between callback buffer and leave only the remaining
    // incomplete line in that buffer
    while((offset = proc_data.data.indexOf('\n')) >= 0) {
      // extract a single line of data from the start of the string
      // pay attention to windows line endings if there are any!
      var line = proc_data.data.substring(0,
                     (offset > 0 &&
                      proc_data.data.charAt(offset-1) == '\r') ?
                         offset - 1 : offset);

      // is this a "comment" that contains meta information in a JSON blob?
      if(line.charAt(0) == '#') {
        try { proc_data.options = JSON.parse(line.substring(1)); }
        catch(e) { console.log("Error parsing proc otions: " + e); }
        // set a timeout to stop this run if requested in meta block
        if(proc_data.options.timeout)
          proc_data.timeout = setTimeout(kill_func,
                                         proc_data.options.timeout * 1000);
      }
      else {
        // if this line has data in it, simply shuffle it into
        // list of lines that will need to be processed
        if(line.length) proc_data.lines.push(line);

        // however if the line doesn't have data in it it's a blank
        // line, meaning we should attempt to process everything that
        // we've collected so far up until this point
        else handle_output(d, cb, instance);
      }

      // discard this line from the buffer we're using between
      // "data" callbacks and move onto processing the next one
      // if there is (or keep it for next callback if there isn't)
      proc_data.data = proc_data.data.substring(offset+1);
    }
  });

  // when the command is done, mark it as no longer running.
  cmd.on('exit', function(code, signal) {
    d.running = false;
  });

  // if there's any error running the command, log it and remove
  // it from the list of scripts we're running
  cmd.on('error', function(err) {
    console.log("Error on " + d.command + " (" + err + "), removing from scripts");
    proc_data.data = "";
    d.running = false;
    delete scripts[d.name];
  });
}

// this is called from the "webserver" part, it's job is:
//   1. Run all scripts
//   2. Put the output as JSON into the passed result
function run_scripts(req, res, which) {
  // this is a per-request counter that lets us know
  // when all scripts have returned and it's safe to
  // stringify out the output.
  req.nad_run_count = 0;

  // this is the data structure we're going to populate
  // with the results and eventually stringify out as JSON
  var set = {};

  // called when complete to actually send 'set' out as JSON
  var send_complete = function() {
    if(req.nad_run_count != 0) return;
    res.writeHead(200, { 'Content-Type': 'application/json' });
    res.write(JSON.stringify(set));
    res.end();
  };

  // if they asked for a particular script and it didn't exist
  // then just send a 404
  if(which && !(which in scripts)) {
    res.writeHead(404);
    res.end();
  }
  else {
    // otherwise we're going to populate "set" and send it back
    // either just with the script they asked for in which or,
    // if nothing was passed in which, with every script

    // first work out how many scripts we're going to wait to run
    for(var file in scripts) {
      if ( which && file != which ) continue;
      req.nad_run_count++;
    }

    // add one for the push_script
    if (!which) req.nad_run_count++;

    // call init script for each script (which will run it) and
    // then when it returns in the callback populate set with
    // the result.  Keep track of how many scripts are left to run
    //
    for(var file in scripts) {
      if ( which && file != which ) continue;
      init_script(scripts[file], req, function(d, results, name) {
        req.nad_run_count--;
        set[name] = results;
        send_complete();  // only sends if all scripts are done
      });
    }

    // call the global push receiver script to spit out anything collected
    // over http
    if (!which) {
        init_script(push_script, req, function(d, results, name) {
            req.nad_run_count--;
            if (results !== null) {
                for (const group in results) {
                    set[group] = results[group];
                }
                if (debugdir) {
                    dutil.write_debug_output(name, ["Returning push_receiver data", JSON.stringify(results)], debugdir, wipedebugdir);
                }
            }
            send_complete();  // only sends if all scripts are done
        });
    }

    send_complete(); // only sends if there were no scripts to run
  }
}

////////////////////////////////////////////////////////////////////////
// process web requests
////////////////////////////////////////////////////////////////////////

// this is the callback that's called whenever something connects
// to our webserver (either any of the http or the https servers)

function handler(req, res) {
    var bodyChunks = [];
    req.addListener('data', function(chunk) {
        bodyChunks.push(chunk);
    });

  // wait for the request to be completely formed (by registering
  // a callback on the 'end' event) and then send back the result
  req.addListener('end', function() {
    var m, path = url.parse(this.url).pathname;
    var body = Buffer.concat(bodyChunks).toString();

    // request for meta-info about the scripts
    if(/^\/inventory/.test(path)) {
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.write(JSON.stringify(scripts));
      res.end();
      return;
    }

    // request to run all scripts and return results
    if(/^\/(?:run)?$/.test(path))
      return run_scripts(req, res);

    // request to run just one script and return results
    if(m = /^\/run\/(.+)$/.exec(path))
      return run_scripts(req, res, m[1]);

    // wmi
    if(m = /^\/wmi\/get-categories$/.test(path))
      return circwmi.get_categories(res);
    if(m = /^\/wmi\/(.+)$/.exec(path))
      return circwmi.get_counters_for_category(res, m[1], debugdir, wipedebugdir);

    //plugin
    if (m = /^\/write\/(.+)$/.exec(path)) {
        if (req.method !== 'PUT' && req.method !== 'POST') {
            res.writeHead(405, "Method Not Allowed", { 'Allow' : 'PUT, POST' });
            res.end();
            return;
        }
        if (debugdir) {
            dutil.write_debug_output(m[1], ["Receiving push_receiver data", body], debugdir, wipedebugdir);
        }
        push_script.obj.some_data(m[1], body);
        res.writeHead(200, "OK", { 'Content-Type': 'text/plan' });
        res.end();
        return;
    }
    res.writeHead(404);
    res.end();
  });

  // if we don't have a data listener the stream starts paused in node 10+
  req.addListener('data', function(){});
}

////////////////////////////////////////////////////////////////////////
// autoconfig with circonus
////////////////////////////////////////////////////////////////////////

function configure_circonus() {
  var error = false;
  if ( ! /^[0-9a-fA-F]{4}(?:[0-9a-fA-F]{4}-){4}[0-9a-fA-F]{12}$/.test(auth_token)  ) {
    console.log("--authtoken should be a UUID.");
    error = true;
  }
  if ( target === null ) {
    console.log("--target is required.");
    error = true;
  }
  if ( brokerid === null || ! /^\d+$/.test(brokerid) ) {
    console.log("--brokerid is required and should be an integer.");
    error = true;
  }
  if ( configfile === null ) {
    console.log("--configfile is required.");
    error = true;
  }
  if ( error ) {
    process.exit(1);
  }

  nadapi.configure(auth_token, target, hostname, brokerid, configfile, api_options);
}

////////////////////////////////////////////////////////////////////////
// start webservers
////////////////////////////////////////////////////////////////////////

if ( ! api_setup ) {
    // initialize: look for modules, and register a handler to
    // rescan the modules every time the directory with the modules
    // in it changes
    fs.watchFile(configdir, onchange(rescan_modules));
    rescan_modules();

    // add our specialized push script that handles incoming POST data from any local data spurters
    push_script = new Object();
    push_script.name = "dumpster";
    push_script.native_plugin = true;
    push_script.running = false;
    var module = require("push_receiver");
    push_script.obj = new module();

    // listen on all non-secure ports
    try {
      for(var i=0; i<port.length; i++)
        http.createServer(handler).listen(port[i][0] , port[i][1]);
    } catch(e) {
      console.error("Failed to start server on port", port, e);
      process.exit(-1);
    }

    // listen on all secure ports
    try {
      for(var i=0; i<sslport.length; i++)
        https.createServer(creds, handler).listen(sslport[i][0], sslport[i][1]);
    } catch(e) {
      console.error("Failed to start server on port", sslport, e);
      process.exit(-1);
    }
}

////////////////////////////////////////////////////////////////////////
// setup optional reverse sockets
////////////////////////////////////////////////////////////////////////


// this is a module local dict to hold the reverse connections we make
// in setup_reverse.  it exists merely to keep the connections alive which
// act as proxies and all incoming calls to this nad instance will be "pull"
// style HTTP GET requests and be handled in the normal "handler" function.
var revs = {}

var revSetupAttempts = 0;
var maxRevSetupAttempts = 5;

function getRetryInterval() {
    var minRetryInterval = 5 * 1000; // 5 seconds
    var maxRetryInterval = 30 * 1000; // 30 seconds
    return Math.floor(Math.random() * (maxRetryInterval - minRetryInterval + 1)) + minRetryInterval;
}

function setup_reverse() {
    var noit;

    try {
        noit = require('noit-connection');
    }
    catch (e) {
        console.error('ERROR: Failed to load noit-connection module -', e);
        // explicit request to use reverse connections but, unable to establish the connection
        // exit intentionally so there is a record in logging and service management can handle
        // a persistently failing service in its usual manner.
        process.exit(1);
    }

    var getNoitCreds = function getNoitCreds() {
        var noitCreds = null;
        var credFunc = null;

        if (cafile) {
            noitCreds = noit.hashToCreds({ca: cafile});
        }
        else {
            // crypto.createCredentials is deprecated in v4+
            if (typeof tls.createSecureContext === 'function') {
                credFunc = tls.createSecureContext;
            }
            else if (typeof crypto.createCredentials === 'function') {
                credFunc = crypto.createCredentials;
            }
            else {
                console.error('ERROR: Unable to determine correct method to create secure context for reverse connection.');
                process.exit(1);
            }

            noitCreds = credFunc({ ca: [
                '-----BEGIN CERTIFICATE-----',
                'MIID4zCCA0ygAwIBAgIJAMelf8skwVWPMA0GCSqGSIb3DQEBBQUAMIGoMQswCQYD',
                'VQQGEwJVUzERMA8GA1UECBMITWFyeWxhbmQxETAPBgNVBAcTCENvbHVtYmlhMRcw',
                'FQYDVQQKEw5DaXJjb251cywgSW5jLjERMA8GA1UECxMIQ2lyY29udXMxJzAlBgNV',
                'BAMTHkNpcmNvbnVzIENlcnRpZmljYXRlIEF1dGhvcml0eTEeMBwGCSqGSIb3DQEJ',
                'ARYPY2FAY2lyY29udXMubmV0MB4XDTA5MTIyMzE5MTcwNloXDTE5MTIyMTE5MTcw',
                'NlowgagxCzAJBgNVBAYTAlVTMREwDwYDVQQIEwhNYXJ5bGFuZDERMA8GA1UEBxMI',
                'Q29sdW1iaWExFzAVBgNVBAoTDkNpcmNvbnVzLCBJbmMuMREwDwYDVQQLEwhDaXJj',
                'b251czEnMCUGA1UEAxMeQ2lyY29udXMgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MR4w',
                'HAYJKoZIhvcNAQkBFg9jYUBjaXJjb251cy5uZXQwgZ8wDQYJKoZIhvcNAQEBBQAD',
                'gY0AMIGJAoGBAKz2X0/0vJJ4ad1roehFyxUXHdkjJA9msEKwT2ojummdUB3kK5z6',
                'PDzDL9/c65eFYWqrQWVWZSLQK1D+v9xJThCe93v6QkSJa7GZkCq9dxClXVtBmZH3',
                'hNIZZKVC6JMA9dpRjBmlFgNuIdN7q5aJsv8VZHH+QrAyr9aQmhDJAmk1AgMBAAGj',
                'ggERMIIBDTAdBgNVHQ4EFgQUyNTsgZHSkhhDJ5i+6IFlPzKYxsUwgd0GA1UdIwSB',
                '1TCB0oAUyNTsgZHSkhhDJ5i+6IFlPzKYxsWhga6kgaswgagxCzAJBgNVBAYTAlVT',
                'MREwDwYDVQQIEwhNYXJ5bGFuZDERMA8GA1UEBxMIQ29sdW1iaWExFzAVBgNVBAoT',
                'DkNpcmNvbnVzLCBJbmMuMREwDwYDVQQLEwhDaXJjb251czEnMCUGA1UEAxMeQ2ly',
                'Y29udXMgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MR4wHAYJKoZIhvcNAQkBFg9jYUBj',
                'aXJjb251cy5uZXSCCQDHpX/LJMFVjzAMBgNVHRMEBTADAQH/MA0GCSqGSIb3DQEB',
                'BQUAA4GBAAHBtl15BwbSyq0dMEBpEdQYhHianU/rvOMe57digBmox7ZkPEbB/baE',
                'sYJysziA2raOtRxVRtcxuZSMij2RiJDsLxzIp1H60Xhr8lmf7qF6Y+sZl7V36KZb',
                'n2ezaOoRtsQl9dhqEMe8zgL76p9YZ5E69Al0mgiifTteyNjjMuIW',
                '-----END CERTIFICATE-----'
            ].join('\n')});
        }

        creds.rejectUnauthorized = false;

        return noitCreds;
    };

    var circapi_cb = function(code, err, data) {
        if (err) {
            revSetupAttempts++;
            var retryInterval = getRetryInterval();
            console.error('WARN: reverse connection -', code, err, data,
                'trying again in', Math.round(retryInterval / 1000)+'s. Attempt',
                revSetupAttempts, 'of', maxRevSetupAttempts);
            if (revSetupAttempts >= maxRevSetupAttempts) {
                console.error('ERROR: Failed to setup reverse connection after', maxRevSetupAttempts, 'attempts.');
                // explicit request to use reverse connections but, unable to establish the connection
                // exit intentionally so there is a record in logging and service management can handle
                // a persistently failing service in its usual manner.
                process.exit(1);
            }
            setTimeout(setup_reverse, retryInterval);
            return;
        }

        if (data === null || typeof data !== 'object' || (Array.isArray(data) && data.length === 0)) {
            if (check_bundle_id === null) {
                console.error('ERROR: configuration for reverse - searching yielded no applicable json:nad check for', hostname);
            }
            else {
                console.error('ERROR: configuration for reverse - unable to retrieve check', check_bundle_id, 'object with API.');
            }
            // explicit request to use reverse connections but, incorrect configuration prevents
            // correct functionality. exit intentionally so there is a record in logging and
            // service management can handle a persistently failing service in its usual manner.
            process.exit(1);
        }

        var check = {};

        if (Array.isArray(data)) {
            check = data[0];
        } else {
            check = data;
        }

        if (!check.hasOwnProperty('_reverse_connection_urls')) {
            console.error('ERROR: invalid check, does not contain a reverse connection URL.', check._cid);
            process.exit(1);
        }

        if (!Array.isArray(check._reverse_connection_urls) || check._reverse_connection_urls.length === 0) {
            console.error('ERROR: invalid check, reverse connection URL attribute is invalid.', check._cid);
            process.exit(1);
        }

        check._reverse_connection_urls.forEach(function(url) {
            var m = /^mtev_reverse:\/\/(.+):(\d+)\/([^.]+)$/.exec(url);

            if (m) {
                revs[url] = new noit.connection(m[2], m[1], getNoitCreds());
                revs[url].reverse(m[3], '127.0.0.1', port[0][0]);
            }
            else {
                var isFatal = check._reverse_connection_urls.length === 1;
                console.error(isFatal ? 'ERROR:' : 'WARN:', 'invalid reverse connection URL,', isFatal ? 'exiting.' : 'skipping.', url);
                if (isFatal) {
                    process.exit(1);
                }
            }
        });
    };

    circapi.setup(auth_token, 'nad', api_options);

    if (check_bundle_id === null) {
        circapi.get('/check_bundle?f_type=json:nad&f_target=' + hostname, null, circapi_cb);
    }
    else {
      circapi.get('/check_bundle/' + check_bundle_id, null, circapi_cb);
    }
}

////////////////////////////////////////////////////////////////////////
// setuid
////////////////////////////////////////////////////////////////////////

function post_boot() {
  if(process.setuid && drop_uid) {
    console.log("Dropping privileges: " + drop_uid);
    process.setuid(drop_uid);
  }
  if(attempt_reverse) setup_reverse();
}

////////////////////////////////////////////////////////////////////////
// done
////////////////////////////////////////////////////////////////////////

// initial setup is all done now
// at this point if we've started servers etc the process will keep
// running even though we "fall off the end" of the code here

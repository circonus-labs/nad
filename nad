#!/usr/bin/env node
'use strict';
//
// Toss executables (scripts too) in /etc/node-agent.d
// Each program should produce lines as follows:
//    <name><whitespace><type>
// or:
//    <name><whitespace><type><whitespace><value>
//
// The first indicates the value is present an null
// the second indicates the valus is present and specific
//

// require //////////////////////////////////////////////////////////////

var fs = require('fs'),
    os = require('os'),
    sys = require('sys'),
    http = require('http'),
    url = require('url'),
    path = require('path'),
    crypto = require('crypto'),
    circapi = require('circonusapi2'),
    nadapi = require('nad_circapi'),
    circwmi = require('circwmi'),
    dutil = require('debug_util'),
    spawn = require('child_process').spawn;

// "globals" ///////////////////////////////////////////////////////////

var booted = false;
var ext = /(?:\.([^.]+))?$/;

// cache of previous results of running scripts
// this is responded with if a script is still running when
// a request for a new value comes in (which is common with long
// running scripts that periodically output values)
var past_results = {};

// a data structure representing all scripts (aka plugins/native
// plugins.)  Each value in the objcect contains an object that
// has properties relating to the script.
var scripts = {};

// a collection incating which scripts that have been run once
// already
var scripts_once = {};

// ssl credentials
var creds = {};

// The UID that we should attempt to "drop" to if specified
// on the command line so we don't have to keep running as root
var drop_uid = 0;

// The script "generation".  A global counter that's incremented
// each time we scan for new scripts on disk.
var generation = 0;

// a flag set from the command line that indicates we just want
// to run the index and then exit
var do_index = false;

// command line options for api setup
var api_options = {};
var api_setup = false;
var attempt_reverse = false;
var auth_token = null;
var target = null;
var cafile = null;
var hostname = os.hostname();
var brokerid = null
var configfile = null;
var debugdir = null;                        // if set, a dir to write debug logs to
var wipedebugdir = false;                  // if true, wipe debug logs clean before each write
var platform = process.platform;
var is_windows = (platform === "win32");    // windows

// procre is a regular expression that captures
// the main part of a filename (i.e. without)
var procre = null;
if (is_windows) {
  procre = /^(?!\.)([^\\]*?)(?:\..*)$/;
} else {
  procre = /^(?!\.)([^\/]*?)(?:\..*)$/;
}

var configdir = '/opt/circonus/etc/node-agent.d',
    port = [],
    defaultport = [ [ 2609, null ] ],
    sslport = [],
    verify = false;

////////////////////////////////////////////////////////////////////////
// help
////////////////////////////////////////////////////////////////////////

function help(err) {
  console.log(process.argv[1] + "\n" +
              "\t-h\t\t\tthis help message\n" +
              "\t-i\t\t\toffline inventory\n" +
              "\t-c <configdir>\t\tconfig dir\n" +
              "\t-p [ip:]<port>\t\tunsecured port\n" +
              "\t-s [ip:]<secureport>\tsecured port\n" +
              "\t-v\t\t\tverify secured traffic\n" +
              "\t-r\t\t\tattempt reverse connection\n" +
              "\t--authtoken\t\tCirconus API auth token to use, if passed will attempt to configure via the Circonus API then exit.\n" +
              "\t--target\t\tTarget Circonus will use to contact this host.\n" +
              "\t--hostname\t\tHostname used in check and graph names, if not passed we will attempt to look it up.\n" +
              "\t--brokerid\t\tID of the Circonus broker to configure the check on.\n" +
              "\t--cafile\t\tpath to CA certificate file.\n" +
              "\t--configfile\t\tName of the file in the config directory to use for Circonus configuration.\n" +
              "\t--debugdir\t\tCreate debug files for each script and write them to this directory.\n" +
              "\t--wipedebugdir\t\tWipe debug files clean before each write.\n" +
              "\t--apihost\t\tOverride the host for the Circonus API server (default: api.circonus.com)\n" +
              "\t--apiport\t\tOverride the port for the Circonus API server (default: 443)\n" +
              "\t--apipath\t\tOverride the path for the Circonus API server (default: /v2)\n" +
              "\t--apiprotocol\t\tOverride the protocol for the Circonus API server (default: https)\n" +
              "\t--apiverbose\t\tOutput API traffic to STDERR\n"
            );
  if(err) {
    console.log("\nError: " + err + "\n");
    process.exit(-1);
  }
}

////////////////////////////////////////////////////////////////////////
// index
////////////////////////////////////////////////////////////////////////

// this code is used to generate an "index" of what is in the
// in the config directory.  It's triggered by passing the "-i"
// flag on the command line

function index(dir) {

  // attempt to change to this directory or die trying
  try { process.chdir(dir); }
  catch (e) {
    console.log("Cannot use configdir: " + configdir);
    console.log(e.message);
    process.exit(-1);
  }

  // a collection of files that are listed in the JSON in the catalog
  // files (the ".index.json" files) in each directory
  var catalog = {};

  var active  = {};

  // a collection of files that are "missing" (i.e. listed in the catalog
  // files but not in the directories / inaccessible somehow)
  var missing = {};

  // a recursive function that once called will recurse down through
  // the directories reading the ".index.json" files and examining the
  // files and popuating the catalog / active / missing variables
  function build_catalog(dir) {
    dir = dir || "";

    // attempt to read the ".index.json" catalog file in the directory
    // passed in, and then process each entry in that catalog.
    // Remember each file that isn't in the directory
    try {
      var c = fs.readFileSync(path.join(".", dir, ".index.json"));
      var j = JSON.parse(c);
      catalog[dir] = j;
      for(var script in j) {
        try {
          var info = fs.statSync(path.join(".", dir, script));
          if(!info.isFile() || (!(is_windows) && (!(info.mode & parseInt('0100',8))))) throw Exception("");
        } catch(e) { missing[path.join(dir, script)] = true; }
      }
    } catch(e) { }

    // recurse into all subdirectories and call ourselves again
    var files = fs.readdirSync(path.join(".", dir));
    for(var i=0; i<files.length; i++) {
      var info = fs.statSync(path.join(".", dir, files[i]));
      if(info && info.isDirectory()) {
        build_catalog(path.join(dir, files[i]));
      }
    }
  }
  build_catalog();

  // read the actual scripts in the config directory
  // ...run the loop for each
  var files = fs.readdirSync(".");
  var base = fs.realpathSync(".") + path.sep;
  for(var i=0; i<files.length; i++) {
    var m = procre.exec(files[i]);
    if(!m) continue;
    var extension = ext.exec(files[i])[1];
    if ((extension === "conf") || (extension === "json")) continue;
    var info = fs.lstatSync(files[i]);
    var realpath = files[i];
    if(info.isSymbolicLink()) info = fs.statSync(files[i]);

    // if this is executable (or we're running on windows)
    if(info.isFile() && (is_windows || info.mode & parseInt('0100',8))) {
      var realpath = fs.realpathSync(files[i]);
      if(realpath.indexOf(base) == 0)
        realpath = realpath.substr(base.length);
      active[realpath] = m[1];
    }
  }

  // generate debug output
  for(var module in catalog) {
    for(var script in catalog[module]) {
      var m = procre.exec(script);
      if(!m) console.log("! " + script + ": MALFORMED NAME");
      else {
        var extension = ext.exec(script)[1];
        if ((extension === "conf") || (extension === "json")){
          console.log("! " + script + ": CANNOT EXECUTE " + extension + " FILES");
          continue;
        }
        var file = path.join(module, script);
        var desc = catalog[module][script];
        var on = (file in active) ? "*" : " ";
        if(file in missing) on = "!";
        delete active[file];
        console.log(on + " " +
                    path.join(module, m[1]) + ": " + desc);
      }
    }
  }
  var first = true;
  for(var file in active) {
    if(first) { console.log("\n  !!! Rogue scripts !!!"); first = false; }
    console.log("* " + file + ": ???");
  }
}

////////////////////////////////////////////////////////////////////////
// process commmand line arguments
////////////////////////////////////////////////////////////////////////

for(var i=2; i<process.argv.length; i++) {
  switch(process.argv[i]) {

    // display help
    case "-h": help(); process.exit(-1);

    // set the config dir
    // (internally we resolve this to the real path after processing symlinks)
    case "-c": configdir = fs.realpathSync(process.argv[++i]); break;

    // offline inventory
    case "-i": do_index = true; break;

    // switch to this uid after starting
    // (only if node supports it on the host os)
    case "-u": drop_uid = parseInt(process.argv[++i]); break;

    // specify one or more ports (and, optionally, IP) to listen for
    // http requests on either in the form "8080" or "127.0.0.1:8080"
    case "-p": {
      var p = process.argv[++i].split(/:/);
      if(p.length == 1) p.unshift(null);
      if(p.length != 2) help("-p [ip:]port");
      port.push( [ parseInt(p[1]), p[0] ] );
      break;
    }

    // specify one or more ports (and, optionally, IP) to listen for
    // https requests on either in the form "4443" or "127.0.0.1:4443"
    case "-s": {
      var p = process.argv[++i].split(/:/);
      if(p.length == 1) p.unshift(null);
      if(p.length != 2) help("-s [ip:]port");
      sslport.push( [ parseInt(p[1]), p[0] ] );
      break;
    }

    // should we verify using a certifcate authority the
    // SSL certificate presented?
    case "-v": verify = true; break;

    //// options for autoconfig with circonus api ////

    case "--authtoken": {
        auth_token = process.argv[++i];
        api_setup=true;
        break;
    }
    case "-r": attempt_reverse = true; break;
    case "--target": target = process.argv[++i]; break;
    case "--hostname": hostname = process.argv[++i]; break;
    case "--brokerid": brokerid = process.argv[++i]; break;
    case "--cafile": cafile = process.argv[++i]; break;
    case "--configfile": configfile = fs.realpathSync(process.argv[++i]); break;
    case "--debugdir": debugdir = process.argv[++i]; break;
    case "--wipedebugdir": wipedebugdir = true; ++i; break;
    case "--apihost": api_options['host'] = process.argv[++i]; break;
    case "--apiport": api_options['port'] = process.argv[++i]; break;
    case "--apipath": api_options['path'] = process.argv[++i]; break;
    case "--apiprotocol": api_options['protocol'] = process.argv[++i]; break;
    case "--apiverbose": api_options['verbose'] = true; break;

    //// unknown option, just display the helptext ////

    default: help("unknown argument: " + process.argv[i]);
  }
}

if (attempt_reverse) api_setup = false;

// if we're just indexing, do that then quit
if(do_index) {
  index(configdir);
  process.exit(0);
}

// if we're just setting up circonus, do that
if(api_setup) {
  configure_circonus();
}

// setup ports / ssl
if(port.length == 0) port = defaultport;
if(port.length == 0 && sslport.length == 0)
  help("must specify at least one of -p and -s");
if(sslport.length > 0) {
  try {
    // Setup creds
    creds.key = fs.readFileSync(path.join(configdir, "na.key")).toString();
    creds.crt = fs.readFileSync(path.join(configdir, "na.crt")).toString();
    if(verify) creds.ca = fs.readFileSync(path.join(configdir, "na.ca")).toString();
  } catch(e) {
    console.log("Make sure:");
    console.log("\tyour key is available: " + path.join(configdir, "na.key"));
    console.log("\tyour cert is available: " + path.join(configdir, "na.crt"));
    if(verify)
      console.log("\tyour ca is available: " + path.join(configdir, "na.ca"));
    console.log("\n" + e);
    process.exit(-1);
  }
}

////////////////////////////////////////////////////////////////////////
// scanning for plugins (both native and non-native)
////////////////////////////////////////////////////////////////////////

// a handy function returning a callback that will
// determine if a file has changed on not.
// Used by rescan_modules
function onchange(cb) {
  return function(c,p) {
    if(c.ino != p.ino || c.size != p.size || c.mtime.valueOf() != p.mtime.valueOf() || c.mode != p.mode)
      cb();
  };
}

// run each script in scripts that hasn't had an initial
// run yet (and then remember it _has_ had an initial run)
function initial_pass() {
  for(var which in scripts) {
    if(!(which in scripts_once)) {
      init_script(scripts[which], null, function() {});
      scripts_once[which] = true;
    }
  }
  if(!booted) {
    post_boot();
    booted = true;
  }
}

// look on disk for updates to the config dir where
// we keep all our modules (aka plugins / aka scripts)
function rescan_modules() {

  // this keeps track of how many filesystem stats we have
  // "in progress" and are still waiting for callbacks on
  var progress = 0;

  // this is a handy private function that goes through
  // all the scripts in our scripts object and removes
  // any that haven't had their generation number updated
  // to our current generation number once we've done
  // scanning
  var sweep = function () {

    // don't do this while we're still waiting for
    // stat requests that are in progress
    if(progress != 0) return;

    // clear out any out of date scripts
    for(var t in scripts) {
      if(scripts[t].generation < generation) {
        fs.unwatchFile(scripts[t].command);
        delete scripts[t];
        delete scripts_once[t];
      }
    }

    // run the initial run for any new scripts
    initial_pass();
  };

  // generation is the global number of times rescan_modules has been
  // called.  Each time we rescan our modules we increase it
  // by one.
  generation++;

  // look in the config directory
  fs.readdir(configdir, function(err, files) {

    // bomb out if there's any error (we don't do any fancy
    // error handling or attempt any form of recovery)
    if (err) {
      console.log("Can't read config dir '"+configdir+"': "+err);
      process.exit(-1);
    }

    // inc our reference count
    progress++;

    // for each file in the config directory
    for(var i = 0; i < files.length; i++) {

      // check if the file is of the form something.something
      // and if it doen't match, ignore this file
      // (this regex will contain a platform dependent regex)
      var m = procre.exec(files[i]);
      if(!m) continue;

      // ignore files that are something.conf or something.json
      // these are config files, not plugins
      var extension = ext.exec(files[i])[1];
      if ((extension === "conf")||(extension === "json")) continue;

      var filename = path.join(configdir, files[i]);

      // stop watching the file for updates
      fs.unwatchFile(filename);

      // note we need to wait for another stat callback to be
      // called before we're done
      progress++;

      // stat the file
      fs.stat(filename, (function(filename, name) {
        return function(serr, sb) {

          // rewatch the file for future updates.  i.e. if the file changes
          // again later then retrigger this rescan_modules routine
          if(sb && sb.isFile())
            fs.watchFile(filename, onchange(rescan_modules));

          // if the file is something we should deal with
          // (is a file, and either ends in .js or is executable, or we're running on
          // windows where everything is considered executable)
          if(sb && sb.isFile() && (is_windows || /\.js$/.test(filename) || sb.mode & parseInt('0111',8))) {
            // setup the details in the scripts object for this file
            if(!(name in scripts)) scripts[name] = {};
            var d = scripts[name];
            d.name = name;
            d.generation = generation;
            d.command = filename;
            d.native_plugin = /\.js$/.test(filename);
            d.running = false;
            d.sb = sb;

            // if this is a "native plugin", i.e. a plugin written in
            // javascript with a ".js" extension then simply load
            // the code directly into node and then create
            // an instance 'obj' to shove in the scripts data structure
            if(d.native_plugin) {
              var module = require(d.command);
              d.obj = new module();
            }

            // Only remove items on initial scan
            if (generation == 1) {
              dutil.init_debug(name, debugdir);
            }
          }
          progress--;
          sweep();
        }
      })(filename,m[1]));
    }
    progress--;
    sweep();
  });
}

////////////////////////////////////////////////////////////////////////
// executing scripts
////////////////////////////////////////////////////////////////////////

function init_script(d, req, cb) {
  if(d.running) {
    cb(d, past_results[d.name]);
    return;
  }

  get_config(req, d, cb);
}

// per script config
function get_config(req, d, cb) {
  console.log(d.name);
  fs.exists(path.join(configdir, d.name + ".json"), function(exists) {
    if ( exists ) {
      console.log("hey, a config file");
      fs.readFile(path.join(configdir, d.name + ".json"), function(err, data) {
        if (err) throw err;
        var json_config = JSON.parse(data);

      console.log(json_config);

        var instance_count = 0;
        for ( var instance in json_config ) instance_count++;

        // Add the number of time we will run this script to our
        // total run_count so we don't finish early.
        if ( instance_count > 1 ) req.nad_run_count += instance_count - 1;
        for ( var instance in json_config ) {
          run_script(d, cb, req, json_config[instance], d.name + "`" + instance);
        }
      });
    }
    else {
      run_script(d, cb, req, [], d.name);
    }
  });
}

// utility function;  Returns the callback wrapped in an
// additional function that that stores the results in
// past results before calling the callback
function past_set_cb(cb) {
  return function(_d, _r, _i) {
    past_results[_i] = _r;
    cb(_d,_r,_i);
  }
};

// runs a single script / native plugin and then fire a callback
//   d is the object for the script that's stored in 'scripts'
//   cb is what we call back when done
//   req is the request object (passed to native plugins)
//   args is any arguments that came from the per script config file
//   instance is
function run_script(d, cb, req, args, instance) {

  // mark it as running
  // (we don't re-run scripts that are still running)
  d.running = true;

  // per process data
  var proc_data = {
    // incomplete line of data buffered between
    // callbacks.  This will be
    data: '',

    // complete lines of data that have yet to
    // be handled (parsed for JSON and/or tab
    // file format.)  We only parse the output
    // when we reach the end of the output or a
    // blank line
    lines: [],

    options: {}
  };

  // mark that we're starting now
  d.last_start = +(new Date());

  // if this is a native plugin then all we need to do
  // is call the run method on the instance stored within d.obj
  // and we're done, so return
  if(d.native_plugin) {
    d.obj.run(d, past_set_cb(cb), req, args, instance);
    return;
  }

  // execute the command
  var cmd = spawn(d.command, args);
  var kill_func = function() {
    cmd.stdin.destroy();
    cmd.stdout.destroy();
    cmd.stderr.destroy();
    cmd.kill();
  };

  // create a function that can handle output from the procss we
  // just created.  This will be called from the code below whenever
  // we reach the end of the process output, or a blank line is found in
  // the output
  var handle_output = function(d, cb, instance) {
    if(proc_data.timeout) clearTimeout(proc_data.timeout);
    d.last_finish = +(new Date());
    var i, results = {}, parts;

    // if someone has specified a debug dir, then log out
    // the record we collected to that
    if (debugdir) {
      dutil.write_debug_output(d.name, proc_data.lines, debugdir, wipedebugdir);
    }

    // attempt to process the lines as json...
    try { results = JSON.parse(proc_data.lines.join(' ')); }
    catch(e) {
      // ... but if that doesn't work, try the tab delim format
      for(i=0; i<proc_data.lines.length; i++) {
        var name, type, space, val, isnull;
        parts = /^\s*(metric\s+)?(\S+)\s+(string|int|float|[iIlLns])(\s*)(.*)$/.exec(proc_data.lines[i]);
        if (parts) {
          name = parts[2];
          type = parts[3];
          space = parts[4];
          val = parts[5];
          isnull = (space.length == 0 || val == "[[null]]");
          type = type.length > 1 ? type === "float" ? "n" : type.substr(0,1) : type;
          results[name] = { '_type': type,
                            '_value': isnull ? null : val
                          };
        }
      }
    }

    // remember the past results
    past_results[instance] = results;

    // execute the callback
    cb(d, results, instance);
  };

  // hook up the process so whenever we complete reading data
  // from the process we call "handle_output" and process
  // any remaining data (i.e. any partial line still in
  // our between callback buffer)
  cmd.stdout.on('end', function() {
    handle_output(d, cb, instance);
  });

  // hook up an anonymous function to the process to be called
  // whenever we get output.  The way this works is basically
  // there's two buffers used between calls: proc_data.lines
  // representing all lines of data we haven't processed yet
  // and proc_data.data representing an incomplete line
  cmd.stdout.on('data', function(buff) {
    var offset;

    // append output we collected to the incomplete line buffer
    // we're using to cache data between "data" callbacks
    proc_data.data = proc_data.data + buff;

    // extract each complete line of data that's in the
    // between callback buffer and leave only the remaining
    // incomplete line in that buffer
    while((offset = proc_data.data.indexOf('\n')) >= 0) {
      // extract a single line of data from the start of the string
      // pay attention to windows line endings if there are any!
      var line = proc_data.data.substring(0,
                     (offset > 0 &&
                      proc_data.data.charAt(offset-1) == '\r') ?
                         offset - 1 : offset);

      // is this a "comment" that contains meta information in a JSON blob?
      if(line.charAt(0) == '#') {
        try { proc_data.options = JSON.parse(line.substring(1)); }
        catch(e) { console.log("Error parsing proc otions: " + e); }
        // set a timeout to stop this run if requested in meta block
        if(proc_data.options.timeout)
          proc_data.timeout = setTimeout(kill_func,
                                         proc_data.options.timeout * 1000);
      }
      else {
        // if this line has data in it, simply shuffle it into
        // list of lines that will need to be processed
        if(line.length) proc_data.lines.push(line);

        // however if the line doesn't have data in it it's a blank
        // line, meaning we should attempt to process everything that
        // we've collected so far up until this point
        else handle_output(d, cb, instance);
      }

      // discard this line from the buffer we're using between
      // "data" callbacks and move onto processing the next one
      // if there is (or kep it for next callback if there isn't)
      proc_data.data = proc_data.data.substring(offset+1);
    }
  });

  // when the command is done, mark it as no longer running.
  cmd.on('exit', function(code, signal) {
    d.running = false;
  });

  // if there's any error running the command, log it and remove
  // it from the list of scripts we're running
  cmd.on('error', function(err) {
    console.log("Error on " + d.command + " (" + err + "), removing from scripts");
    proc_data.data = "";
    d.running = false;
    delete scripts[d.name];
  });
}

// this is called from the "webserver" part, it's job is:
//   1. Run all scripts
//   2. Put the output as JSON into the passed result
function run_scripts(req, res, which) {
  // this is a per-request counter that lets us know
  // when all scripts have returned and it's safe to
  // stringify out the output.
  req.nad_run_count = 0;

  // this is the data structure we're going to populate
  // with the results and eventually stringify out as JSON
  var set = {};

  // called when complete to actually send 'set' out as JSON
  var send_complete = function() {
    if(req.nad_run_count != 0) return;
    res.writeHead(200, { 'Content-Type': 'application/json' });
    res.write(JSON.stringify(set));
    res.end();
  };

  // if they asked for a paricular script and it didn't exist
  // then just send a 404
  if(which && !(which in scripts)) {
    res.writeHead(404);
    res.end();
  }
  else {
    // otherwise we're going to populate "set" and send it back
    // either just with the script they asked for in which or,
    // if nothing was passed in which, with every script

    // first work out how many scripts we're going to wait to run
    for(var file in scripts) {
      if ( which && file != which ) continue;
      req.nad_run_count++;
    }

    // call init script for each script (which will run it) and
    // then when it returns in the callback populate set with
    // the result.  Keep track of how many scripts are left to run
    //
    for(var file in scripts) {
      if ( which && file != which ) continue;
      init_script(scripts[file], req, function(d, results, name) {
        req.nad_run_count--;
        set[name] = results;
        send_complete();  // only sends if all scripts are done
      });
    }
    send_complete(); // only sends if there were no scripts to run
  }
}

////////////////////////////////////////////////////////////////////////
// process web requests
////////////////////////////////////////////////////////////////////////

// this is the callback that's called whenever something connects
// to our webserver (either any of the http or the https servers)

function handler(req, res) {
  // wait for the request to be completely formed (by registering
  // a callback on the 'end' event) and then send back the result
  req.addListener('end', function() {
    var m, path = url.parse(this.url).pathname;

    // request for meta-info about the scripts
    if(/^\/inventory/.test(path)) {
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.write(JSON.stringify(scripts));
      res.end();
      return;
    }

    // request to run all scripts and return results
    if(/^\/(?:run)?$/.test(path))
      return run_scripts(req, res);

    // request to run just one script and return results
    if(m = /^\/run\/(.+)$/.exec(path))
      return run_scripts(req, res, m[1]);

    // wmi
    if(m = /^\/wmi\/get-categories$/.test(path))
      return circwmi.get_categories(res);
    if(m = /^\/wmi\/(.+)$/.exec(path))
      return circwmi.get_counters_for_category(res, m[1], debugdir, wipedebugdir);

    res.writeHead(404);
    res.end();
  });

  // if we don't have a data listener the stream starts paused in node 10+
  req.addListener('data', function(){});
}

////////////////////////////////////////////////////////////////////////
// autoconfig with circonus
////////////////////////////////////////////////////////////////////////

function configure_circonus() {
  var error = false;
  if ( ! /^[0-9a-fA-F]{4}(?:[0-9a-fA-F]{4}-){4}[0-9a-fA-F]{12}$/.test(auth_token)  ) {
    console.log("--authtoken should be a UUID.");
    error = true;
  }
  if ( target === null ) {
    console.log("--target is required.");
    error = true;
  }
  if ( brokerid === null || ! /^\d+$/.test(brokerid) ) {
    console.log("--brokerid is required and should be an integer.");
    error = true;
  }
  if ( configfile === null ) {
    console.log("--configfile is required.");
    error = true;
  }
  if ( error ) {
    process.exit(1);
  }

  nadapi.configure(auth_token, target, hostname, brokerid, configfile, api_options);
}

////////////////////////////////////////////////////////////////////////
// start webservers
////////////////////////////////////////////////////////////////////////

if ( ! api_setup ) {
    // initialize: look for modules, and register a handler to
    // rescan the modules every time the directory with the modules
    // in it changes
    fs.watchFile(configdir, onchange(rescan_modules));
    rescan_modules();

    // listen on all non-secure ports
    try {
      for(var i=0; i<port.length; i++)
        http.createServer(handler).listen(port[i][0] , port[i][1]);
    } catch(e) {
      console.log("Failed to start server on port " + port + ": " + e);
      process.exit(-1);
    }

    // listen on all secure ports
    try {
      for(var i=0; i<sslport.length; i++)
        https.createServer(creds).addListener(handler).listen(sslport[i][0], sslport[i][1]);
    } catch(e) {
      console.log("Failed to start server on port " + sslport + ": " + e);
      process.exit(-1);
    }
}

////////////////////////////////////////////////////////////////////////
// setup optional reverse sockets
////////////////////////////////////////////////////////////////////////

var revs = {}

function setup_reverse() {
  var noit;
  try { noit = require('noit'); }
  catch(e) {
    console.log("Failed to load noit module");
    return;
  }
  circapi.setup(auth_token, 'nad', api_options);
  circapi.get('/check_bundle?f_type=json:nad&f_target=' + hostname, null,
    function(code, err, data) {
      if(typeof(data) == 'object' && data.length == 1) {
        var check = data[0];
        if(check._reverse_connection_urls && check._reverse_connection_urls.length > 0) {
          check._reverse_connection_urls.forEach(function(url) {
            var m = /^mtev_reverse:\/\/(.+):(\d+)\/([^.]+)$/.exec(url);
            if(m) {
              var creds = crypto.createCredentials({ca:
"-----BEGIN CERTIFICATE-----\n" +
"MIID4zCCA0ygAwIBAgIJAMelf8skwVWPMA0GCSqGSIb3DQEBBQUAMIGoMQswCQYD\n" +
"VQQGEwJVUzERMA8GA1UECBMITWFyeWxhbmQxETAPBgNVBAcTCENvbHVtYmlhMRcw\n" +
"FQYDVQQKEw5DaXJjb251cywgSW5jLjERMA8GA1UECxMIQ2lyY29udXMxJzAlBgNV\n" +
"BAMTHkNpcmNvbnVzIENlcnRpZmljYXRlIEF1dGhvcml0eTEeMBwGCSqGSIb3DQEJ\n" +
"ARYPY2FAY2lyY29udXMubmV0MB4XDTA5MTIyMzE5MTcwNloXDTE5MTIyMTE5MTcw\n" +
"NlowgagxCzAJBgNVBAYTAlVTMREwDwYDVQQIEwhNYXJ5bGFuZDERMA8GA1UEBxMI\n" +
"Q29sdW1iaWExFzAVBgNVBAoTDkNpcmNvbnVzLCBJbmMuMREwDwYDVQQLEwhDaXJj\n" +
"b251czEnMCUGA1UEAxMeQ2lyY29udXMgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MR4w\n" +
"HAYJKoZIhvcNAQkBFg9jYUBjaXJjb251cy5uZXQwgZ8wDQYJKoZIhvcNAQEBBQAD\n" +
"gY0AMIGJAoGBAKz2X0/0vJJ4ad1roehFyxUXHdkjJA9msEKwT2ojummdUB3kK5z6\n" +
"PDzDL9/c65eFYWqrQWVWZSLQK1D+v9xJThCe93v6QkSJa7GZkCq9dxClXVtBmZH3\n" +
"hNIZZKVC6JMA9dpRjBmlFgNuIdN7q5aJsv8VZHH+QrAyr9aQmhDJAmk1AgMBAAGj\n" +
"ggERMIIBDTAdBgNVHQ4EFgQUyNTsgZHSkhhDJ5i+6IFlPzKYxsUwgd0GA1UdIwSB\n" +
"1TCB0oAUyNTsgZHSkhhDJ5i+6IFlPzKYxsWhga6kgaswgagxCzAJBgNVBAYTAlVT\n" +
"MREwDwYDVQQIEwhNYXJ5bGFuZDERMA8GA1UEBxMIQ29sdW1iaWExFzAVBgNVBAoT\n" +
"DkNpcmNvbnVzLCBJbmMuMREwDwYDVQQLEwhDaXJjb251czEnMCUGA1UEAxMeQ2ly\n" +
"Y29udXMgQ2VydGlmaWNhdGUgQXV0aG9yaXR5MR4wHAYJKoZIhvcNAQkBFg9jYUBj\n" +
"aXJjb251cy5uZXSCCQDHpX/LJMFVjzAMBgNVHRMEBTADAQH/MA0GCSqGSIb3DQEB\n" +
"BQUAA4GBAAHBtl15BwbSyq0dMEBpEdQYhHianU/rvOMe57digBmox7ZkPEbB/baE\n" +
"sYJysziA2raOtRxVRtcxuZSMij2RiJDsLxzIp1H60Xhr8lmf7qF6Y+sZl7V36KZb\n" +
"n2ezaOoRtsQl9dhqEMe8zgL76p9YZ5E69Al0mgiifTteyNjjMuIW\n" +
"-----END CERTIFICATE-----"});
              creds.rejectUnauthorized = false;
              revs[url] = new noit.connection(m[2],m[1],
                            cafile ? noit.utils.hashToCreds({ca:cafile}) : creds);
              revs[url].reverse(m[3], '127.0.0.1', port[0][0]);
            }
          });
        } else {
          console.log("configuration error for reverse: no URLs found");
        }
      } else {
        console.log("configuration error for reverse: no check found (hostname mismatch?)");
      }
  });
}

////////////////////////////////////////////////////////////////////////
// setuid
////////////////////////////////////////////////////////////////////////

function post_boot() {
  if(process.setuid && drop_uid) {
    console.log("Dropping privileges: " + drop_uid);
    process.setuid(drop_uid);
  }
  if(attempt_reverse) setup_reverse();
}

////////////////////////////////////////////////////////////////////////
// done
////////////////////////////////////////////////////////////////////////

// initial setup is all done now
// at this point if we've started servers etc the process will keep
// running even though we "fall off the end" of the code here
